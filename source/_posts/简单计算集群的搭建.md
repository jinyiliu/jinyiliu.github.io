---
title: 简单计算集群的搭建
date: 2021-7-19 15:24:58
toc: true
tags:
    - Linux
    - bnu
---

这是北师大理论宇宙学课题组的小型计算集群的使用说明以及搭建过程。

<!--more-->

# **使用计算集群**

分为普通用户的使用和管理者的使用。

## **普通用户**

1. 三个主机分别是novamaria、vivy和diva，需要使用校园网登录。三台主机之间互相知道对方的主机名，如果你已经登录到novamaria上，可以直接通过`ssh diva`或者`ssh vivy`访问另外两台主机。
1. 修改密码需要在三台主机上都进行修改。
1. 三个主机的用户目录`/home`内容一致，在novamaria上编辑的脚本，在vivy上也能看到，普通用户只需要选择一个计算资源宽裕的主机进行计算。
1. 文件夹`/data`是用来存放大型数据的（比如模拟等），程序脚本可以存放到各自用户目录下，`/data`文件夹一共44T的存储空间，存放数据的时候注意用`df -h`查看还有多少余量，不要超过存储上限，不然别人的数据就被覆盖了。
1. 在`/share`文件夹里有常用的公共资源，比如Anaconda3和Anaconda2的安装包等。如果对共享资源有别的需要可以直接提意见。
1. 如需连网可以使用[深澜命令行客户端](https://github.com/ice-tong/SrunClient)登录校园网关，在`/share`里也有资源。
1. 服务器大家一起共享，请大家为其它跑程序的同学考虑一下！一个用户最多占用所有计算资源的70%，也就是占满两台服务器左右，发现非法占用直接杀死进程，如果要跑大型并行程序，到vivy和diva上跑，因为novamaria是集群主节点，很多数据传输的工作在此服务器上进行，跑满的话所有`/home`下的操作都会变慢。
1. 有需要用`sudo`安装的包软件，直接提意见。


## **管理者**

**新建用户**

因为没有NIS服务，所以创建新用户的时候需要在三个节点上都创建用户，具体操作

{% codeblock lang:bash line_number:false %}
sudo adduser foo        # 在三个主机上都新建同样的用户并查看UID和GID是否一致
sudo mkdir /data/foo    # 新建一个属于该用户存储数据的目录
chown foo /data/foo     # 修改权限
chgrp foo /data/foo     # 修改权限
{% endcodeblock %}

**删除用户**

{% codeblock lang:bash line_number:false %}
sudo deluser foo
sudo rm -rf /data/foo
{% endcodeblock %}

需要注意的是`useradd`和`adduser`并不一样，`userdel`和`deluser`并不一样。




# **搭建计算集群**

搭建小组成员：刘晋弋，申嵩聿，王正一，韩嘉康，李竹海，贾涵筇，胡老师
服务器放置地点：科技楼A229小黑屋

三台服务器是一模一样的机型和配置，每个服务器有58个核，1T的固态硬盘和4T的机械硬盘，非常适合搭建计算集群。

<div style="text-align:center">
{% asset_img server.jpg 500 '"" "科技楼小黑屋里的服务器排列"' %}
</div>

## TODO

- 在这里`/etc/update-motd.d`更改欢迎语
- 调整风扇转速，风扇转速上限解锁
- 免VPN校外登录
- 听说有一个只能在自己目录下面`sudo`的东西

## **准备工作**

**硬件准备**

插线板
千兆交换机
显示器
键盘
五类网线四根
Ubuntu Desktop 18.04 LTS启动盘

**系统重装**

使用Ubuntu Desktop 18.04 LTS启动U盘重装系统。如果存在硬盘清理不干净的情况，可以使用Security Erase来清理所有固态和机械（耗时较长），再进行安装系统的过程。三台服务器健康状况良好。


## **网络配置**
服务器之间使用千兆交换机连接（最大传输速度为125 Mb/s），所有服务器在校园网内随意连接。

| Hostname  | IP            |
| :---      | :---          |
| novamaria | xx.xx.xx.133  |
| vivy      | xx.xx.xx.60   |
| diva      | xx.xx.xx.201  |

需要注意的是，尽量使用独立网卡，使用`ifconfig`可以查看有几个网卡，独立网卡名称开头是enp，集成网卡名称开头是eno。

服务器最好使用静态IP（Static IP）而不是动态IP（DHCP），但是因为在校园网内部IP和网卡MAC是绑定的，IP够用的情况下不会出现IP被占用的情况，所以这里不进行设置，如果因为机器重启导致IP发生变化，直接修改机器配置即可。


## **软件安装**

下面是一些之后需要用到的软件，先提前安装好

{% codeblock lang:bash line_number:false %}
$ sudo apt-get update
$ sudo apt-get install
openssh-client openssh-server \
vsftpd \
net-tools xfsprogs lvm2 \
nfs-server nfs-client rpcbind glusterfs-server glusterfs-client \
git \
vim neovim python-neovim python3-neovim python3-pip \
gfortran build-essential golang nodejs php \
cmake automake pkg-config autoconf libtool \
lsscsi inxi \
curl zsh tmux ranger tree htop screen \
msttcorefonts \
libncurses5-dev libssl-dev zlib1g-dev \
{% endcodeblock %}


## **SSH**

这一步使得三台服务器之间能够通过主机名直接访问，在`/etc/hosts`中添加

{% codeblock /etc/hosts line_number:false %}
# IP                    Hostname
xx.xx.xx.133    	novamaria
xx.xx.xx.60        	vivy
xx.xx.xx.201       	diva
{% endcodeblock %}

之后我们将novamaria称为主节点，作为各项服务的服务端，其它两个主机作客户端。如果需要进一步配置免密访问，可以先用`ssh-keygen`生成密钥和公钥，然后再`ssh-copy-id`将公钥复制到另外两台服务器上。

## **NFS**

网络文件系统（Network File System）是用来在不同主机之间共享文件的，参考了[How To Set Up an NFS Mount on Ubuntu 18.04](https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-18-04)和 [Linux下配置NIS和NFS /home目录](https://blog.csdn.net/liuck/article/details/60955507)。

这里主要说明如何实现`/home`文件夹的NFS部署过程。后续可以在vivy上部署`/opt`文件夹用来共享一些比如OneAPI之类的计算包，也可以在diva上部署`/share`文件夹用来存放公共资源，更好地利用三个服务器的固态。

### **NFS服务端**

在novamaria上编辑`/etc/exports`文件，添加下面两行

{% codeblock /etc/exports line_number:false %}
/home   xx.xx.xx.60/24(insecure,rw,sync,no_root_squash,no_subtree_check)
/home   xx.xx.xx.201/24(insecure,rw,sync,no_root_squash,no_subtree_check)
{% endcodeblock %}

然后`sudo exportfs -a`，重启NFS服务

{% codeblock line_number:false %}
sudo service nfs-kernel-server restart
{% endcodeblock %}

### **NFS客户端**

先将原来的`/home`进行备份（放置后续操作失误），在vivy和diva上编辑`/etc/fstab`文件，添加下面一行就可以重启进行挂载

{% codeblock line_number:false %}
novamaria:/home	/home	nfs	noatime,noauto,x-systemd.automount,x-systemd.device-timeout=10s 0	2
{% endcodeblock %}

最后需要重启服务端和客户端。

## **GlusterFS**

GlusterFS是分布式文件存储系统。首先将每个计算节点上的四块机械硬盘整合到一个逻辑卷中（[如何在Linux中创建/配置LVM](https://linux.cn/article-12670-1.html)），可以通过`lsblk`查看未挂载的机械硬盘的设备名，确认需要纳入逻辑卷中的设备名

{% codeblock lang:bash line_number:false %}
sudo pvcreate /dev/sda /dev/sdb /dev/sdc /dev/sdd       # create physical volumn
sudo pvs                                                # display physical volumn
sudo vgcreate vg /dev/sda /dev/sdb /dev/sdc /dev/sdd	# create volumn group
sudo vgs vg                                             # display volumn gruop
sudo lvcreate -n lva -l 100%FREE vg                     # create logical volumn
sudo lvs /dev/vg/lva                                    # display logical volumn
sudo mkfs -t xfs /dev/vg/lva                            # 格式化逻辑卷
sudo mkdir -p /glusterfs                                # 创建要挂载的目录
sudo mount /dev/vg/lva /glusterfs                       # 挂载
{% endcodeblock %}

然后在`/etc/fstab`里添加

{% codeblock /etc/fstab line_number:false %}
/dev/vg/lva     /glusterfs     xfs     defaults        0       0
{% endcodeblock %}

当每个计算节点上4块机械都整合到一个逻辑卷中之后，进行GlusterFS的搭建（[如何在Ubuntu 18.04上使用GlusterFS设置高可用性存储](https://www.linuxidc.com/Linux/2018-08/153727.htm)），首先在每个节点上启动并查看GlusterFS的状态

{% codeblock lang:bash line_number:false %}
sudo systemctl start glusterd
sudo systemctl enable glusterd
sudo systemctl status glusterd
{% endcodeblock %}

在主节点novamaria上配置信任池

{% codeblock lang:bash line_number:false %}
sudo gluster peer probe vivy
sudo gluster peer probe diva
sudo gluster peer status
{% endcodeblock %}

此时信任池是空的，创建完之后可以在vivy或者diva上查看信任池状态。在novamaria上创建卷


{% codeblock lang:bash line_number:false %}
sudo gluster volume create gfsv transport tcp {novamaria,vivy,diva}:/glusterfs/brick
{% endcodeblock %}

gfsv是GFS Volume的缩写，这里需要注意我们不需要进行备份，在创建卷的时候没必要加上replica这个参数。查看卷的信息，启动卷

{% codeblock lang:bash line_number:false %}
sudo gluster volume info
sudo gluster volume start gfsv
{% endcodeblock %}


<div style="text-align:center">
{% asset_img gfsv_info.png 350 '"" "卷的信息是这样的"'%}
</div>

然后在主节点novamaria进行挂载，机械硬盘主要用于存储数据所以命名为`/data`

{% codeblock lang:bash line_number:false %}
sudo mkdir /data
sudo mount -t glusterfs novamaria:/gfsv /data
{% endcodeblock %}

在diva和vivy中的`/etc/fstab`文件里添加下面这一行（NFS）

{% codeblock /etc/fstab line_number:false %}
novamaria:/gfsv   /data     glusterfs    defaults,_netdev   0       0
{% endcodeblock %}

可以使用`df -h`查看GlusterFS在novamaria上的挂载情况。

`/data` 平均读出速度达到220M/s，平均写入速度达到100M/s，对比之下非分布式的系统（也就是在同一个主机内进行读写操作）可以达到的读写速度分别是330M/s和180M/s，而远程文件系统（通过网线进行传输）受限于网卡、交换机的带宽，仅能达到读写速度110M/s和50M/s，GlusterFS总体而言是它们的平均值，也可以看到分布式存储的特点。




## **失败的NIS**

网络信息服务（Network Infomation Service）提供共享用户信息，一个用户在Server上可以登录，那么在Client上也能登录，共享了用户、群组的信息。配置分为Server端和Client端。参考这些资源

[NIS Installation and Configuration](https://www.youtube.com/watch?v=02JMK6cCnI4)
[[How-To] Automounting Home Directories with NIS and NFS](https://boubakr92.wordpress.com/2013/12/14/automounting-home-directories-with-nis-and-nfs/)
[nstalling NIS server on Ubuntu 18.04 LTS](https://linuxhint.com/install_nis_server_ubuntu/)
[总结下最近建立集群的步骤以及NIS服务器搭建](https://blog.csdn.net/qq_38663663/article/details/107206322)

因为有严重的BUG没有解决，做完NIS之后Client端登录会明显变慢，最终并未做成 NIS 服务！

<br/>

<div style="text-align:center">
{% asset_img Vivy.jpg 300 '"" "Vivy和Diva的命名来自2021年四月番《Vivy: Fluorite Eye's Song》"' %}
</div>

<br/>
